\documentclass[12pt, letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\title{CS387 - Applied Cryptography}
\author{\'Angel Sola Orbaiceta}
\date{December 2021}

\begin{document}

\begin{titlepage}
  \maketitle
\end{titlepage}

% ======================================================================
% ======================================================================
%          SECTION
% ======================================================================
% ======================================================================
\section{Concepts}

Given a message $m \in M$, where $M$ is the set of all possible messages, and a key $k \in K$, where $K$ is the set of all possible keys, an encryption function $E$ can be defined as:
\[
  E: M \times K \to C
\]
where $c \in C$ is the \emph{ciperthext} (being $C$ the set of all possible ciphertexts).
Conversely, a decryption function $D$ can be defined as:
\[
  D: C \times K \to M
\]

The \textbf{correctness property} states that, for all messages and keys, decrypting the result of encrypting a message must result in the message itself.
Mathematically:

\[
  \forall m,k: D_k (E_k(m)) = m
\]

The \textbf{security property} states that the ciphertext reveals nothing about the key or original message.

\subsection{One-Time Pad}

The one-time pad is based in the XOR ($\oplus$) function.
The XOR function satisfies the property that any value XOR-ed with itself equals zero: $x \oplus x = 0$.
The one-time pad uses this property so that, by using a key that's the same size as the ciphertext, we can do:

\[
  c = m \oplus k\\
\]
\[
  m = c \oplus k
\]

The one-time pad encryption and decryption functions are implemented in the \emph{source/one\_time\_pad.py} file.

\subsection{Perfect Cipher}

Recall that given two events $A$ and $B$ in the same probability space, the \textbf{conditional probability} of $B$ given that $A$ occured is:

\[
  P(B|A) = \frac{P(A \cap B)}{P(A)}
\]

Now, given two messages, $m$ and $m^*$ drawn from the set of messages $M$ are encrypted using a key $k \in K$ to produce a cypertext $c \in C$,
a \textbf{perfect cipher} must hold that:

\[
  P \left( m = m^* | E_k \left( m \right) = c \right) = P \left( m = m^* \right)
\]

We can now prove that the one-time pad is a perfect cipher as follows.
For the one-time pad:

\[
  P \left( E_k \left( m \right) = c \right) = \sum_{m_i \in M} \sum_{k_i \in K} \frac{P(E_{k_i} (m_i) = c)}{|M| \times |K|}
  = \frac{|M|}{|M| \times |K|}
  = \frac{1}{|K|}
\]
and, assuming a uniform distribution for the key space:

\[
  P \left( m = m^* \cap E_k(m) = c \right)
  = P(m = m^*) \times P(k = k^*)
  = \frac{P(m = m^*)}{|K|}
\]
Therefore:

\[
  P \left( m = m^* | E_k(m) = c \right) = \frac{\frac{P(m = m^*)}{|K|}}{\frac{1}{|K|}}
  = P(m = m^*)
\]
which means that the ciphertext reveals nothing about the key or original message.

\paragraph{Shanon's theorem} If a cipher is perfect, it must be impractical ($|K| \geq |M|$).


% ======================================================================
% ======================================================================
%          SECTION
% ======================================================================
% ======================================================================
\section{Application of Symmetric Ciphers}

\paragraph{Kolmogorov complexity} The complexity $K$ of a sequence $s$ ($K(s)$) is the length of the shortest possible description of $s$.
$s$ is random if $K(s) = |s| + C$.
The Kolmogorov complexity is uncomputable.

\paragraph{A Pseudo-Random Number Generator (PRNG)} produces a long sequence of seemingly random bytes given an initial seed value.
In Linux, \emph{dev/random} can be used as a randomness pool.

\subsection{Modes Of Operation}

We assume the message we want to encrypt or decrypt can be broken into $n$ blocks of size $b$:

\[
  m = m_0, m_1, m_2, \dots, m_{n-1}
\]

\paragraph{Electronic Codebook Mode} (ECB) each block is encrypted independently from each other:

\[
  c_i = E_k (m_i)
\]
and decryption:

\[
  m_i = D_k (c_i)
\]

The problem with ECB mode is that it doesn't hide repetition: equal blocks encrypt to equal ciperthexts.
To run a cipher using the ECB mode of operation:

\begin{verbatim}
  $ py symmetric/block_cli.py -e -m ecb -f <file> -k <key>
\end{verbatim}

\paragraph{Cipher Block Chaining Mode (CBC)} the output of each block is XOR-ed with the input to the next block.
Encryption:

\[
  c_i = E_k (m_i \oplus c_{i - 1})
\]
and if an \textbf{initialization vector} is used, the first block:

\[
  c_0 = E_k (m_0 \oplus IV)
\]
and decryption:

\[
  m_i = D_k (c_i) \oplus c_{i-1}
\]
\[
  m_0 = D_k(c_0) \oplus IV
\]

To run a cipher using the CBC mode of operation:

\begin{verbatim}
  $ py symmetric/block_cli.py -e -m cbc -f <file> -k <key>
\end{verbatim}

\paragraph{Counter Mode (CTR)} uses a counter that increments for each block, which concatenated with a \textbf{nonce} is passed to the encryption function.
The result is then XOR-ed with the message blocks.
The benefit of CTR is that blocks can be encrypted and decrypted in parallel.

\[
  c_i = E_k(\mathtt{nonce} || i) \oplus m_i
\]
and decryption:

\[
  m_i = c_i \oplus D_k(\mathtt{nonce} || i)
\]

If the block size is 32 bytes (256 bits), the nonce and the counter can be 16 bytes (128 bits) each.
When concatenated, both make a 32 bytes sequence.

To run a cipher using the CTR mode of operation:

\begin{verbatim}
  $ py symmetric/block_cli.py -e -m ctr \
    -f <file> \
    -k <key> \
    -n <nonce>
\end{verbatim}

\subsection{Protocols}

A \textbf{protocol} is a precisely defined sequence of steps agreed upon two parties.
A \textbf{cryptographic protocol} involves shared secrets between the two parties, and, for it to be \textbf{secure}, it must provide some guarantees even if some participants cheat.


\subsection{Cryptographic Hash Functions}

A \textbf{hash function} $h = H(x)$ is a function defined over a large input domain which output is of a fixed --usually small-- length.
A regular hash function has the following properties:

\begin{itemize}
  \item compression: a large input domain is mapped to a small fixed output
  \item well distributed: $P(H(x) = i) \sim \frac{1}{N}$, where $N$ is the size of the output
\end{itemize}
Additionally, \textbf{cryptographic hash functions} must have the following properties:

\begin{itemize}
  \item pre-image resistance ("one-way ness"): given $h = H(x)$, it's hard to find $x$
  \item weak collision resistance: given $h = H(x)$, it's hard to find any $x'$ such that $H(x') = h$
  \item strong collision resistance: it's hard to find any pair $x$ and $y$ such that $H(x) = H(y)$
\end{itemize}

Given an ideal hash function with $N$ possible outputs, an attacker is expected to need:
\begin{itemize}
  \item weak: $\sim N$ guesses to find $x'$ where $H(x') = h$
  \item strong: $\sim \sqrt{N}$ guesses to find $x$, $y$ where $H(x) = H(y)$.
\end{itemize}

\paragraph{Salted password scheme} To securely store passwords and avoid dictionary attacks --where the attacker precomputes a list of password hashes--,
a good scheme is to hash the result of concatenating a \textbf{salt} (sequence or random bits) with the password: $H(\mathtt{salt} || \mathtt{password})$.
The salt can be stored together with the password; it's just used to avoid the dictionary attack.


% ======================================================================
% ======================================================================
%          SECTION
% ======================================================================
% ======================================================================
\section{Key Distribution}

With symmertic ciphers, the parties need to share a secret before they can communicate securely: \textbf{the key}.
But distributing keys among all possible pairs of parties who want to communicate isn't practical.

\paragraph{Pairwise distribution} If $n$ people want to communicate with each other, that'd mean that $\frac{n \times (n - 1)}{2}$ different keys need to be shared among them.
For 100 people, this would be $\frac{100 \times 99}{2} = 4950$ keys.
This is obviously impractical.

\paragraph{Trusted third party} A third party might be trusted to maintain a secret with each person who wants to communicate.
Then, whenever two persons --say Alice and Bob-- want to communicate, they must first ask the third party to create a new secret key for them.

\subsection{Diffie-Hellman Key Exchange}

Published in 1976 by Whitfield Diffie and Martin Hellman in their famous paper ``New Directions in Cryptography''.

\paragraph{Diffie-Hellman Key Exchange} This protocol --assuming Alice and Bob want to share a private key-- works as follows:

\begin{enumerate}
  \item Alice and Bob agree on two shared numbers: a large prime number $q$ and $g$, a primitive root\footnote{$g$ is a primitive root of $q$ if $\forall x \in \lbrace 1, 2, \dots, q-1\rbrace \exists k$ such that $g^k = x$.} of $q$
  \item Alice chooses a random secret value $x_A = \lbrace 0, 1 \rbrace^n$ and computes $y_A = g^{x_A} \: \mathtt{mod} \: q$
  \item Bob chooses a random secret value $x_B = \lbrace 0, 1 \rbrace^n$ and computes $y_B = g^{x_B} \: \mathtt{mod} \: q$
  \item Alice and Bob exchange the $y_A$ and $y_B$ values
  \item Alice can compute the shared secret key: $k_{AB} = y_B^{x_A} \: \mathtt{mod} \: q$
  \item Bob can compute the shared secret key: $k_{BA} = y_A^{x_B} \: \mathtt{mod} \: q$
\end{enumerate}

We can prove that the keys that both Alice and Bob compute are the same ($k_{AB} = k_{BA}$) since, for Alice:

\[
  k_{AB} = y_B^{x_A} \: \mathtt{mod} \: q = g^{x_B \times x_A} \: \mathtt{mod} \: q
\]
and for the case of Bob:

\[
  k_{BA} = y_A^{x_B} \: \mathtt{mod} \: q = g^{x_A \times x_B} \: \mathtt{mod} \: q
\]

A \textbf{passive eavesdropper} would know about $q$, $g$, $y_A$ and $y_B$, so, how can be sure they wouldn't be able to compute the private key $k_{AB}$?
An adversary would need to be able to solve the discrete logarithm problem in order to compute the shared secret key, and we know the discrete logarithm problem is very hard to solve.

\paragraph{The Discrete Logarithm Problem} With continuous logarithms, if we're given the equation $a^x = b$, we know of efficient ways to compute $x$ if we rearrange the equation as $x = \log_a b$.
In the discrete logarithm case: computing $x$ in $a^x = b \: \mathtt{mod} \: n$, there isn't a known way to solve it.
One thing to note about $a^x = b \: \mathtt{mod} \: n$ is that it doesn't always have a solution (as opposed to the continuous case), but if $n$ is a prime number and $a$ is a generator\footnote{A number $g$ is a generator if its powers form a permutation of the numbers in $Z_n$: $\lbrace 1, 2, \dots, n-1 \rbrace$.} number, then there must be a solution for $x$.

Computing $a^n$ can be done using $O(\log n)$ multiplications.
Modular exponentiation is linear in the size (bits to represent) of the power.

\paragraph{Rabin-Miller and AKS Primality Tests} To test if a large number is prime in a reasonable amount of time.


% ======================================================================
% ======================================================================
%          SECTION
% ======================================================================
% ======================================================================
\section{Asymmetric Cryptosystems}

Using a pair of keys, one public $k_{pub}$ and one private $k_{priv}$, Alice can encrypt a message using $k_{pub}$ and send it to Bob --the owner of $k_{priv}$-- so he can be the only one to decrypt it and read it.
In this case, the correctness property can be stated as:

\[
  D_{k_{priv}} (E_{k_{pub}} (m)) = m
\]

This pair of keys can also be used for \textbf{signing documents}.
The owner of $k_{priv}$ can sign (encrypt) the hash of the document using $k_{priv}$, and then $k_{pub}$ can be used to ensure that the decrypted hash matches the actual hash of the signed document.

\subsection{RSA}

The name comes from the initials of its inventors: Ron Rivest, Adi Shamir and Len Adleman.
In the RSA protocol, the public key is made up of two numbers $e$ and $n$:

\[
  k_{pub} = (e, n)
\]
and the private key follows suit:

\[
  k_{priv} = (d, n)
\]
The number $n$ is the product $n = q \times q$, where $p$ and $q$ are two large prime numbes.
Encryption and decryption are then performed as follows:

\[
  E_{k_{pub}} (m) = m^e \: \mathtt{mod} \: n
\]
\[
  D_{k_{priv}} (c) = c^d \: \mathtt{mod} \: n
\]

In order for RSA to be invertible ($D_{k_{priv}} (E_{k_{pub}} (m)) = m$), the following must hold:

\[
  m^{ed - 1} = 1 \: \mathtt{mod} \: n
\]
Therefore $e$, $d$ and $n$ need to be selected such that $\forall m \in Z_n: m^{ed-1} \equiv 1 \: \mathtt{mod} \: n$.

\paragraph{Fermat's Little Theorem} states that $a^{n-1} \equiv 1 \: \mathtt{mod} \: n$ if $n$ is a prime number and $gcd(a, n) = 1$.

\paragraph{Euler's Theorem} states that if $gcd(a, n) = 1$, then $a^{\phi(n)} \equiv 1 \: \mathtt{mod} \: n$.
Here $\phi(n)$ is the \textbf{totient function}, the number of positive integers smaller than $n$ that are relatively prime to $n$.
Recall that two positive integers are said to be \textbf{relatively prime} if their greatest common divisor is 1.

If $n = pq$ where $p$ and $q$ are prime, then $\phi(n) = \phi(p) \phi(q)$.
\end{document}
